{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import z534\n",
    "import SemDiff as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = z534.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurants: 59371\n",
      "querying restaurant reviews\n"
     ]
    }
   ],
   "source": [
    "restaurants_cursor = db.businesses.find({'list_of_categories': 'Restaurants'})\n",
    "\n",
    "restaurants = []\n",
    "\n",
    "for item in restaurants_cursor:\n",
    "    restaurants.append(item)\n",
    "        \n",
    "print(\"Number of restaurants: {}\" \\\n",
    "      .format(len(restaurants)))\n",
    "\n",
    "print('querying restaurant reviews')\n",
    "pos_reviews, neg_reviews = z534.aggregate_reviews(db, \n",
    "                                                  business_category = 'Restaurants',\n",
    "                                                  split='stars', \n",
    "                                                  review_count = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = min(len(pos_reviews), len(neg_reviews))\n",
    "pos_reviews_filt = pos_reviews[:length]\n",
    "neg_reviews_filt = neg_reviews[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame(pos_reviews_filt)\n",
    "neg_df = pd.DataFrame(neg_reviews_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/bsobolik/Documents/semantic_difference/data/'\n",
    "ensure_dir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.to_csv(DATA_DIR + 'pos_restaurant_text.csv')\n",
    "neg_df.to_csv(DATA_DIR + 'neg_restaurant_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SemDiff as sd\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.929516077041626 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:48:23,258 : INFO : collecting all words and their counts\n",
      "2019-04-26 14:48:23,258 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.8263890743255615 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:48:24,937 : INFO : PROGRESS: at sentence #10000, processed 1136056 words and 289612 word types\n",
      "2019-04-26 14:48:26,749 : INFO : PROGRESS: at sentence #20000, processed 2275556 words and 452359 word types\n",
      "2019-04-26 14:48:27,358 : INFO : collected 501669 word types from a corpus of 2640210 words (unigram + bigrams) and 22631 sentences\n",
      "2019-04-26 14:48:27,359 : INFO : using 501669 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2019-04-26 14:48:27,361 : INFO : collecting all words and their counts\n",
      "2019-04-26 14:48:27,362 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:48:32,017 : INFO : PROGRESS: at sentence #10000, processed 1048359 words, keeping 24526 word types\n",
      "2019-04-26 14:48:36,292 : INFO : PROGRESS: at sentence #20000, processed 2092084 words, keeping 31393 word types\n",
      "2019-04-26 14:48:37,671 : INFO : collected 33784 word types from a corpus of 2423685 raw words and 22631 sentences\n",
      "2019-04-26 14:48:37,672 : INFO : Loading a fresh vocabulary\n",
      "2019-04-26 14:48:37,737 : INFO : effective_min_count=50 retains 3182 unique words (9% of original 33784, drops 30602)\n",
      "2019-04-26 14:48:37,739 : INFO : effective_min_count=50 leaves 2231559 word corpus (92% of original 2423685, drops 192126)\n",
      "2019-04-26 14:48:37,749 : INFO : deleting the raw counts dictionary of 33784 items\n",
      "2019-04-26 14:48:37,752 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2019-04-26 14:48:37,753 : INFO : downsampling leaves estimated 1547827 word corpus (69.4% of prior 2231559)\n",
      "2019-04-26 14:48:37,760 : INFO : estimated required memory for 3182 words and 100 dimensions: 4136600 bytes\n",
      "2019-04-26 14:48:37,761 : INFO : resetting layer weights\n",
      "2019-04-26 14:48:37,803 : INFO : training model with 8 workers on 3182 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-04-26 14:48:38,824 : INFO : EPOCH 1 - PROGRESS: at 8.26% examples, 133306 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:39,876 : INFO : EPOCH 1 - PROGRESS: at 15.93% examples, 131512 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:40,885 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 132616 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:41,896 : INFO : EPOCH 1 - PROGRESS: at 34.02% examples, 130700 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:42,952 : INFO : EPOCH 1 - PROGRESS: at 44.85% examples, 130696 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:43,967 : INFO : EPOCH 1 - PROGRESS: at 54.11% examples, 130869 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:45,009 : INFO : EPOCH 1 - PROGRESS: at 65.16% examples, 131693 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:46,054 : INFO : EPOCH 1 - PROGRESS: at 74.70% examples, 132857 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:47,058 : INFO : EPOCH 1 - PROGRESS: at 82.61% examples, 133688 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:48,082 : INFO : EPOCH 1 - PROGRESS: at 90.65% examples, 134011 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:49,107 : INFO : EPOCH 1 - PROGRESS: at 98.30% examples, 134037 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:49,345 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:48:49,346 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:48:49,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:48:49,348 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:48:49,348 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:48:49,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:48:49,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:48:49,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:48:49,351 : INFO : EPOCH - 1 : training on 2423685 raw words (1547776 effective words) took 11.5s, 134153 effective words/s\n",
      "2019-04-26 14:48:50,391 : INFO : EPOCH 2 - PROGRESS: at 8.63% examples, 137157 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:51,407 : INFO : EPOCH 2 - PROGRESS: at 16.28% examples, 135605 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:52,444 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 132040 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:53,478 : INFO : EPOCH 2 - PROGRESS: at 35.00% examples, 132531 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:54,481 : INFO : EPOCH 2 - PROGRESS: at 45.28% examples, 132385 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:55,484 : INFO : EPOCH 2 - PROGRESS: at 54.72% examples, 132578 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:56,530 : INFO : EPOCH 2 - PROGRESS: at 66.22% examples, 133951 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:57,534 : INFO : EPOCH 2 - PROGRESS: at 75.00% examples, 134737 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:58,537 : INFO : EPOCH 2 - PROGRESS: at 82.97% examples, 135354 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:48:59,567 : INFO : EPOCH 2 - PROGRESS: at 90.96% examples, 135445 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:00,602 : INFO : EPOCH 2 - PROGRESS: at 98.66% examples, 135201 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:00,785 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:49:00,786 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:49:00,787 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:49:00,787 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:49:00,788 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:49:00,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:49:00,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:49:00,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:49:00,791 : INFO : EPOCH - 2 : training on 2423685 raw words (1547508 effective words) took 11.4s, 135412 effective words/s\n",
      "2019-04-26 14:49:01,828 : INFO : EPOCH 3 - PROGRESS: at 8.63% examples, 137562 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:02,858 : INFO : EPOCH 3 - PROGRESS: at 16.28% examples, 134864 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:03,875 : INFO : EPOCH 3 - PROGRESS: at 23.11% examples, 128413 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:04,892 : INFO : EPOCH 3 - PROGRESS: at 32.92% examples, 127336 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:05,933 : INFO : EPOCH 3 - PROGRESS: at 43.84% examples, 128426 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:06,981 : INFO : EPOCH 3 - PROGRESS: at 54.11% examples, 130354 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:08,014 : INFO : EPOCH 3 - PROGRESS: at 65.16% examples, 131418 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:09,033 : INFO : EPOCH 3 - PROGRESS: at 74.26% examples, 132242 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:10,069 : INFO : EPOCH 3 - PROGRESS: at 82.25% examples, 132681 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:11,077 : INFO : EPOCH 3 - PROGRESS: at 89.88% examples, 132747 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:12,092 : INFO : EPOCH 3 - PROGRESS: at 97.30% examples, 132470 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:12,470 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:49:12,472 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:49:12,472 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:49:12,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:49:12,473 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:49:12,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:49:12,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:49:12,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:49:12,476 : INFO : EPOCH - 3 : training on 2423685 raw words (1548294 effective words) took 11.7s, 132625 effective words/s\n",
      "2019-04-26 14:49:13,501 : INFO : EPOCH 4 - PROGRESS: at 8.26% examples, 133254 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:14,522 : INFO : EPOCH 4 - PROGRESS: at 15.93% examples, 133423 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:15,560 : INFO : EPOCH 4 - PROGRESS: at 24.02% examples, 132561 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:16,566 : INFO : EPOCH 4 - PROGRESS: at 34.50% examples, 132370 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:17,596 : INFO : EPOCH 4 - PROGRESS: at 45.28% examples, 132745 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:18,602 : INFO : EPOCH 4 - PROGRESS: at 54.72% examples, 132763 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:49:19,618 : INFO : EPOCH 4 - PROGRESS: at 65.68% examples, 133818 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:20,653 : INFO : EPOCH 4 - PROGRESS: at 74.70% examples, 134104 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:21,695 : INFO : EPOCH 4 - PROGRESS: at 82.97% examples, 134953 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:22,737 : INFO : EPOCH 4 - PROGRESS: at 91.29% examples, 135553 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:23,748 : INFO : EPOCH 4 - PROGRESS: at 99.00% examples, 135606 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:23,893 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:49:23,894 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:49:23,894 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:49:23,895 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:49:23,895 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:49:23,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:49:23,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:49:23,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:49:23,899 : INFO : EPOCH - 4 : training on 2423685 raw words (1548453 effective words) took 11.4s, 135698 effective words/s\n",
      "2019-04-26 14:49:24,929 : INFO : EPOCH 5 - PROGRESS: at 8.63% examples, 138571 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:25,948 : INFO : EPOCH 5 - PROGRESS: at 16.28% examples, 135988 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:26,977 : INFO : EPOCH 5 - PROGRESS: at 24.98% examples, 136803 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:28,018 : INFO : EPOCH 5 - PROGRESS: at 36.55% examples, 137475 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:29,050 : INFO : EPOCH 5 - PROGRESS: at 46.87% examples, 136817 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:30,056 : INFO : EPOCH 5 - PROGRESS: at 57.29% examples, 137345 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:31,057 : INFO : EPOCH 5 - PROGRESS: at 68.00% examples, 137961 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:32,100 : INFO : EPOCH 5 - PROGRESS: at 76.80% examples, 138408 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:33,144 : INFO : EPOCH 5 - PROGRESS: at 85.15% examples, 138686 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:34,155 : INFO : EPOCH 5 - PROGRESS: at 93.07% examples, 138641 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:35,056 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:49:35,058 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:49:35,059 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:49:35,060 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:49:35,061 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:49:35,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:49:35,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:49:35,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:49:35,065 : INFO : EPOCH - 5 : training on 2423685 raw words (1548362 effective words) took 11.2s, 138802 effective words/s\n",
      "2019-04-26 14:49:35,066 : INFO : training on a 12118425 raw words (7740393 effective words) took 57.3s, 135186 effective words/s\n",
      "2019-04-26 14:49:35,066 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-04-26 14:49:35,081 : INFO : saving Word2Vec object under /Users/bsobolik/Documents/semantic_difference/data/pos_model.wv, separately None\n",
      "2019-04-26 14:49:35,082 : INFO : not storing attribute vectors_norm\n",
      "2019-04-26 14:49:35,083 : INFO : not storing attribute cum_table\n",
      "2019-04-26 14:49:35,083 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-04-26 14:49:35,131 : INFO : saved /Users/bsobolik/Documents/semantic_difference/data/pos_model.wv\n",
      "2019-04-26 14:49:35,132 : INFO : collecting all words and their counts\n",
      "2019-04-26 14:49:35,133 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2019-04-26 14:49:37,333 : INFO : PROGRESS: at sentence #10000, processed 1450771 words and 345523 word types\n",
      "2019-04-26 14:49:39,987 : INFO : PROGRESS: at sentence #20000, processed 3171182 words and 597415 word types\n",
      "2019-04-26 14:49:40,762 : INFO : collected 657069 word types from a corpus of 3623837 words (unigram + bigrams) and 22631 sentences\n",
      "2019-04-26 14:49:40,763 : INFO : using 657069 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2019-04-26 14:49:40,763 : INFO : collecting all words and their counts\n",
      "2019-04-26 14:49:40,765 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:49:47,203 : INFO : PROGRESS: at sentence #10000, processed 1349845 words, keeping 26504 word types\n",
      "2019-04-26 14:49:54,263 : INFO : PROGRESS: at sentence #20000, processed 2953957 words, keeping 37016 word types\n",
      "2019-04-26 14:49:56,076 : INFO : collected 39310 word types from a corpus of 3376806 raw words and 22631 sentences\n",
      "2019-04-26 14:49:56,076 : INFO : Loading a fresh vocabulary\n",
      "2019-04-26 14:49:56,113 : INFO : effective_min_count=50 retains 3926 unique words (9% of original 39310, drops 35384)\n",
      "2019-04-26 14:49:56,114 : INFO : effective_min_count=50 leaves 3147804 word corpus (93% of original 3376806, drops 229002)\n",
      "2019-04-26 14:49:56,124 : INFO : deleting the raw counts dictionary of 39310 items\n",
      "2019-04-26 14:49:56,126 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-04-26 14:49:56,127 : INFO : downsampling leaves estimated 2210538 word corpus (70.2% of prior 3147804)\n",
      "2019-04-26 14:49:56,136 : INFO : estimated required memory for 3926 words and 100 dimensions: 5103800 bytes\n",
      "2019-04-26 14:49:56,137 : INFO : resetting layer weights\n",
      "2019-04-26 14:49:56,181 : INFO : training model with 8 workers on 3926 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-04-26 14:49:57,231 : INFO : EPOCH 1 - PROGRESS: at 6.88% examples, 135964 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:58,266 : INFO : EPOCH 1 - PROGRESS: at 14.40% examples, 137122 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:49:59,274 : INFO : EPOCH 1 - PROGRESS: at 21.15% examples, 134833 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:00,310 : INFO : EPOCH 1 - PROGRESS: at 27.48% examples, 132181 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:01,330 : INFO : EPOCH 1 - PROGRESS: at 32.10% examples, 124801 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:02,359 : INFO : EPOCH 1 - PROGRESS: at 39.47% examples, 126959 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:03,369 : INFO : EPOCH 1 - PROGRESS: at 45.79% examples, 128303 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:04,395 : INFO : EPOCH 1 - PROGRESS: at 50.88% examples, 129340 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:05,440 : INFO : EPOCH 1 - PROGRESS: at 56.18% examples, 130562 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:06,467 : INFO : EPOCH 1 - PROGRESS: at 61.74% examples, 131233 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:07,500 : INFO : EPOCH 1 - PROGRESS: at 69.08% examples, 132067 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:08,526 : INFO : EPOCH 1 - PROGRESS: at 76.40% examples, 132772 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:09,537 : INFO : EPOCH 1 - PROGRESS: at 82.20% examples, 133271 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:10,543 : INFO : EPOCH 1 - PROGRESS: at 87.35% examples, 133303 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:11,569 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 133460 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:12,602 : INFO : EPOCH 1 - PROGRESS: at 98.68% examples, 133304 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:12,753 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:50:12,754 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:50:12,754 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:50:12,754 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:50:12,755 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:50:12,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:50:12,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:50:12,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:50:12,760 : INFO : EPOCH - 1 : training on 3376806 raw words (2211752 effective words) took 16.6s, 133480 effective words/s\n",
      "2019-04-26 14:50:13,802 : INFO : EPOCH 2 - PROGRESS: at 6.88% examples, 136906 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:14,846 : INFO : EPOCH 2 - PROGRESS: at 14.40% examples, 136913 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:15,864 : INFO : EPOCH 2 - PROGRESS: at 21.46% examples, 136248 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:16,878 : INFO : EPOCH 2 - PROGRESS: at 28.12% examples, 135661 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:17,893 : INFO : EPOCH 2 - PROGRESS: at 35.09% examples, 136379 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:18,905 : INFO : EPOCH 2 - PROGRESS: at 42.03% examples, 136080 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:19,907 : INFO : EPOCH 2 - PROGRESS: at 48.06% examples, 136200 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:20,943 : INFO : EPOCH 2 - PROGRESS: at 52.74% examples, 135909 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:21,945 : INFO : EPOCH 2 - PROGRESS: at 57.81% examples, 136361 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:22,958 : INFO : EPOCH 2 - PROGRESS: at 64.10% examples, 136809 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:23,959 : INFO : EPOCH 2 - PROGRESS: at 70.89% examples, 136858 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:24,983 : INFO : EPOCH 2 - PROGRESS: at 78.11% examples, 137132 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:26,018 : INFO : EPOCH 2 - PROGRESS: at 83.73% examples, 137077 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:27,032 : INFO : EPOCH 2 - PROGRESS: at 88.82% examples, 136706 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:28,054 : INFO : EPOCH 2 - PROGRESS: at 94.19% examples, 136662 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:28,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:50:28,882 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:50:28,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:50:28,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:50:28,883 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:50:28,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:50:28,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:50:28,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:50:28,888 : INFO : EPOCH - 2 : training on 3376806 raw words (2209794 effective words) took 16.1s, 137109 effective words/s\n",
      "2019-04-26 14:50:29,904 : INFO : EPOCH 3 - PROGRESS: at 6.65% examples, 134217 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:30,907 : INFO : EPOCH 3 - PROGRESS: at 14.03% examples, 138192 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:31,933 : INFO : EPOCH 3 - PROGRESS: at 21.46% examples, 138934 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:32,972 : INFO : EPOCH 3 - PROGRESS: at 28.36% examples, 138331 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:33,991 : INFO : EPOCH 3 - PROGRESS: at 35.38% examples, 138435 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:35,005 : INFO : EPOCH 3 - PROGRESS: at 42.54% examples, 138901 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:36,053 : INFO : EPOCH 3 - PROGRESS: at 48.83% examples, 139432 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:37,066 : INFO : EPOCH 3 - PROGRESS: at 53.78% examples, 139238 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:38,103 : INFO : EPOCH 3 - PROGRESS: at 59.26% examples, 139464 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:39,131 : INFO : EPOCH 3 - PROGRESS: at 65.94% examples, 139494 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:40,158 : INFO : EPOCH 3 - PROGRESS: at 72.83% examples, 139528 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:41,162 : INFO : EPOCH 3 - PROGRESS: at 79.76% examples, 139778 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:42,200 : INFO : EPOCH 3 - PROGRESS: at 85.18% examples, 139419 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:43,213 : INFO : EPOCH 3 - PROGRESS: at 90.23% examples, 138855 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:44,226 : INFO : EPOCH 3 - PROGRESS: at 95.39% examples, 138343 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:44,882 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 14:50:44,883 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:50:44,884 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:50:44,884 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:50:44,885 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:50:44,886 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:50:44,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:50:44,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:50:44,890 : INFO : EPOCH - 3 : training on 3376806 raw words (2209760 effective words) took 16.0s, 138178 effective words/s\n",
      "2019-04-26 14:50:45,904 : INFO : EPOCH 4 - PROGRESS: at 6.65% examples, 134650 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:46,936 : INFO : EPOCH 4 - PROGRESS: at 13.75% examples, 133284 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:47,956 : INFO : EPOCH 4 - PROGRESS: at 20.88% examples, 133746 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:48,985 : INFO : EPOCH 4 - PROGRESS: at 27.48% examples, 133220 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:50,006 : INFO : EPOCH 4 - PROGRESS: at 34.10% examples, 133049 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:51,011 : INFO : EPOCH 4 - PROGRESS: at 41.07% examples, 133414 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:52,031 : INFO : EPOCH 4 - PROGRESS: at 47.28% examples, 133633 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:53,038 : INFO : EPOCH 4 - PROGRESS: at 51.61% examples, 133399 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:54,083 : INFO : EPOCH 4 - PROGRESS: at 56.87% examples, 133459 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:55,126 : INFO : EPOCH 4 - PROGRESS: at 62.76% examples, 133716 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:56,139 : INFO : EPOCH 4 - PROGRESS: at 69.72% examples, 133934 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:57,140 : INFO : EPOCH 4 - PROGRESS: at 76.67% examples, 134215 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:58,170 : INFO : EPOCH 4 - PROGRESS: at 82.40% examples, 134401 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:50:59,206 : INFO : EPOCH 4 - PROGRESS: at 87.95% examples, 134537 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:00,219 : INFO : EPOCH 4 - PROGRESS: at 93.00% examples, 134279 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:01,255 : INFO : EPOCH 4 - PROGRESS: at 98.96% examples, 134070 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:01,356 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:51:01,357 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:51:01,358 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:51:01,358 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:51:01,359 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:51:01,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:51:01,360 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:51:01,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:51:01,364 : INFO : EPOCH - 4 : training on 3376806 raw words (2210221 effective words) took 16.5s, 134248 effective words/s\n",
      "2019-04-26 14:51:02,400 : INFO : EPOCH 5 - PROGRESS: at 6.65% examples, 131999 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:03,431 : INFO : EPOCH 5 - PROGRESS: at 14.03% examples, 135278 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:04,453 : INFO : EPOCH 5 - PROGRESS: at 21.46% examples, 137154 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:05,462 : INFO : EPOCH 5 - PROGRESS: at 27.78% examples, 134882 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:06,502 : INFO : EPOCH 5 - PROGRESS: at 34.78% examples, 135117 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:07,549 : INFO : EPOCH 5 - PROGRESS: at 42.30% examples, 136404 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:08,569 : INFO : EPOCH 5 - PROGRESS: at 48.42% examples, 136928 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:09,587 : INFO : EPOCH 5 - PROGRESS: at 53.54% examples, 137657 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:10,606 : INFO : EPOCH 5 - PROGRESS: at 58.81% examples, 137694 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:11,652 : INFO : EPOCH 5 - PROGRESS: at 65.15% examples, 137592 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:12,680 : INFO : EPOCH 5 - PROGRESS: at 71.75% examples, 137226 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:13,722 : INFO : EPOCH 5 - PROGRESS: at 78.96% examples, 137293 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:14,727 : INFO : EPOCH 5 - PROGRESS: at 84.49% examples, 137465 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:15,777 : INFO : EPOCH 5 - PROGRESS: at 89.76% examples, 137183 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:16,780 : INFO : EPOCH 5 - PROGRESS: at 94.92% examples, 136871 words/s, in_qsize 0, out_qsize 0\n",
      "2019-04-26 14:51:17,487 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-26 14:51:17,488 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-26 14:51:17,489 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-26 14:51:17,489 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-26 14:51:17,490 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 14:51:17,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 14:51:17,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 14:51:17,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 14:51:17,494 : INFO : EPOCH - 5 : training on 3376806 raw words (2210758 effective words) took 16.1s, 137152 effective words/s\n",
      "2019-04-26 14:51:17,495 : INFO : training on a 16884030 raw words (11052285 effective words) took 81.3s, 135932 effective words/s\n",
      "2019-04-26 14:51:17,496 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-04-26 14:51:17,513 : INFO : saving Word2Vec object under /Users/bsobolik/Documents/semantic_difference/data/neg_model.wv, separately None\n",
      "2019-04-26 14:51:17,514 : INFO : not storing attribute vectors_norm\n",
      "2019-04-26 14:51:17,515 : INFO : not storing attribute cum_table\n",
      "2019-04-26 14:51:17,516 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-04-26 14:51:17,564 : INFO : saved /Users/bsobolik/Documents/semantic_difference/data/neg_model.wv\n"
     ]
    }
   ],
   "source": [
    "pos_features = sd.preprocess_data(pos_df, text_col='text', verbose=True)\n",
    "neg_features = sd.preprocess_data(neg_df, text_col='text', verbose=True)\n",
    "\n",
    "# First train the model for the positive reviews\n",
    "pos_model = sd.build_gensim_model(pos_features, min_word_count = 50, verbose = True)\n",
    "pos_model.save(DATA_DIR + 'pos_model.wv')\n",
    "\n",
    "# Then the negative reviews\n",
    "neg_model = sd.build_gensim_model(neg_features, min_word_count = 50, verbose = True)\n",
    "neg_model.save(DATA_DIR + 'neg_model.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for a set of antonyms\n",
    "antonyms = [\n",
    "    [\"good\", \"bad\"],\n",
    "    ['always', 'never'],\n",
    "    ['higher', 'lower'],\n",
    "    ['delicious', 'gross'],\n",
    "    ['strong', 'weak'],\n",
    "    ['very', 'slightly'],\n",
    "    ['nice', 'mean'],\n",
    "    ['hot', 'cold'],\n",
    "    ['black', 'white'],\n",
    "    ['worst', 'best'],\n",
    "    ['happy', 'sad'],\n",
    "    ['common', 'exceptional'],\n",
    "    ['fast', 'slow'],\n",
    "    ['average', 'poor'],\n",
    "    ['man', 'woman']   \n",
    "]\n",
    "\n",
    "words = ['customer', 'host', 'food', 'waiter', 'waitress', 'appetizer', 'dinner', 'table', 'drink', 'lunch']\n",
    "models = [pos_model, neg_model]\n",
    "models_names = [\"positive\", \"negative\"]\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "\n",
    "ant_names = []\n",
    "word_list = []\n",
    "for word in words:\n",
    "    for ant in antonyms:\n",
    "        pos_list.append(sd.project_word_on_axis(pos_model, word, ant, k = 3))\n",
    "        neg_list.append(sd.project_word_on_axis(neg_model, word, ant, k = 3))\n",
    "\n",
    "        word_list.append(word)\n",
    "    \n",
    "        ant_names.append(\"{}-{}\".format(ant[0], ant[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antonym</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good-bad</th>\n",
       "      <td>good-bad</td>\n",
       "      <td>0.268884</td>\n",
       "      <td>0.078628</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always-never</th>\n",
       "      <td>always-never</td>\n",
       "      <td>-0.087727</td>\n",
       "      <td>-0.045877</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher-lower</th>\n",
       "      <td>higher-lower</td>\n",
       "      <td>-0.145648</td>\n",
       "      <td>0.363187</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delicious-gross</th>\n",
       "      <td>delicious-gross</td>\n",
       "      <td>-0.054948</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong-weak</th>\n",
       "      <td>strong-weak</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>-0.105997</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         antonym  negative  positive      word\n",
       "good-bad                good-bad  0.268884  0.078628  customer\n",
       "always-never        always-never -0.087727 -0.045877  customer\n",
       "higher-lower        higher-lower -0.145648  0.363187  customer\n",
       "delicious-gross  delicious-gross -0.054948  0.132450  customer\n",
       "strong-weak          strong-weak  0.029937 -0.105997  customer"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'antonym': ant_names, \n",
    "                   'positive': pos_list, \n",
    "                   'negative': neg_list, \n",
    "                   'word': word_list}, \n",
    "                  index = ant_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR + 'yelp_restaurant_pos_neg_semantic_word_axes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = sd.get_shared_words(pos_model, neg_model, topn_words = 10000)\n",
    "frames = []\n",
    "for word in words:\n",
    "    frames.append(sd.model_term_similarity(pos_model, neg_model, word, shared))\n",
    "    \n",
    "pos_neg_model = pd.concat(frames)\n",
    "\n",
    "pos_neg_model.to_csv(DATA_DIR + 'restaurant_pos_neg_interword_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
